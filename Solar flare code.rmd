---
title: "Solar Flare Time Series Analysis"
date: "`r format(Sys.time(), '%d %B, %Y')`"
geometry: left=2.5cm,right=2.5cm,top=1.5cm,bottom=1.5cm
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    highlight: tango
    number_sections: yes
    fig_caption: yes
    theme: paper
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
#```{r, out.width="1000px", echo=FALSE}
#knitr::include_graphics("solarflarelogo.jpg")
#```

# Introduction
With the constant output of energy, and thus data, the Sun represents an ideal object of study for a data scientist. In particular, studying X-ray flux emitted by the Sun can prove to be beneficial to the prolonged safety of our civilization.
Solar flares are large eruptions of electromagnetic radiation from the Sun lasting from minutes to hours. They usually take place in active regions, which are areas on the Sun marked by the presence of strong magnetic fields. These areas are typically associated with sunspot groups. As these magnetic fields evolve, they can reach a point of instability and release energy in a variety of forms. These include electromagnetic radiation, which are observed as solar flares. 

Although, the Earths magnetic field protects us from solar flares, space-earth radio communication and electronic equipment on-board different space probes and satellites can be effected or completely destroyed.
Therefore, in the this report, we set out to study the temporal structure of the the X-ray flux data, its predictive power as well as whether it is possible to predict solar flares.

## Project Objectives

Given the X-ray flux time series, we want to understand these questions:


* Explore and deduce whether the X-ray flux data contains seasonal components.
* Analyze the structure of the data and explore the relationship between X-ray intensity build up and occurrence of solar flares.
* Finally, explore the predictive power of the data at hand and try predicting a future solar flare using a optimally trained model.

# Data Preparation & Processing

## Data Selection

We used the the NASA GOES Satellite data from 1999 to 2019. We downloaded the data from  [source](https://satdat.ngdc.noaa.gov/sem/goes/data/avg/). Then, we took advantage of a custom python script made to scrap data from the source based on the type and granularity of aggregation. The script allowed us to aggregate the data based on any level of aggregation i.e. hourly, daily, monthly, weekly etc. and provided us with the flexibility to take the maximum, minimum, average or any percentile of aggregated data. 

There were a total of 12 CSV files per year and each file contained X-ray flux intensities recorded by GOES every 1 minute.

## Data Aggregation Methodolgy:

Data aggregation was important because 20 years worth of minute wise data creates a lot of noise.R makes it practically impossible to do spectral analysis on minute wise data to explore underlying cyclical trends. We used hourly and daily aggregation to generate two different datasets for achieving different objectives. The idea was to pick top X-ray intensities in the aggregation window because it was in line with the Solar Flare analysis task. Solar Flares happen when X-Ray flux intensifies and breaches a certain threshold. It is however important to note that there can be blips for a very small period of time in the X-ray intensity too due to events other than Solar Flares. It is therefore of extreme importance to account for these other events and distinguish them from Solar Flares. Taking maximum over an aggregated window can result in getting such observations which were most likely driven by other factors as Solar Flares are rare events. The type of aggregation used was percentile based. We selected the percentile based on our definition Solar Flares in terms of X-Ray Intensities. How did we end up selecting the right percentile will be explained below but before that we need to define Solar Flares in terms of X-Ray intensities,

Whenever the X-ray Intensities breach a certain threshold for a minimum of ten minutes or more, we treat this event as one Solar Flare. The Solar Flare can last for few minutes (greater than ten), hours, days or even weeks depending on the solar activity. 

The key to select percentile is to set it corresponding to ten minutes based on the aggregation window. As we have minute-wise data, for hourly aggregation, we chose the percentile which corresponded to the 10th highest observation i.e. in hourly data if we see the threshold being breached at the tenth highest observation then it implies that the threshold was breached for ten minutes or more and hence solar flare occurred. The corresponding percentile for hourly aggregation is given by, $$Percentile = \frac{(60 - 10)*100}{60} = 83.33$$


Thus 83.33 percentile corresponds to the Solar Flare definition for hourly aggregation. 

Generalizing the formula for selection of percentile, 

$$Percentile = \frac{(Minutes{\ }in{\ }Aggregation{\ }Window - Minimum{\ }Minutes{\ }Solar{\ }Flare)*100}{Minutes{\ }in{\ }Aggregation{\ }Window}$$

Similarly, for daily data we input following parameters in the formula,

Minutes in Aggregation Window = 1440

Minimum Minutes Solar Flare = 10

$$Percentile = \frac{(1440 - 10)*100}{1440} = 96.5$$


In addition, we can also convert the raw intensities into flare categories by using the below table (from Stanford Solar Center) to provide another perspective of the data. Finally, since all of the intensities in the dataset are smaller number $<10^{-6}$, we take log transformation on the time series for numerical stability. 

It is important to note here that the threshold mentioned above for X-Ray intensities to be characterized as Solar Flares is $10^{-5}$. 


## Data Processing & Pre-liminary Time Series Analysis

After aggregation, the hourly and daily data is loaded.

### Hourly Data

First loading the hourly data,

```{r echo=F, message=F}

library("readxl")
#data1999<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data1999_perc_60.xlsx",col_names = 'flux')
data2000<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2000_perc_60.xlsx",col_names = 'flux')
data2001<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2012_perc_60.xlsx",col_names = 'flux')
data2002<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2013_perc_60.xlsx",col_names = 'flux')
data2003<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2014_perc_60.xlsx",col_names = 'flux')
data2004<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2015_perc_60.xlsx",col_names = 'flux')
data2005<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2016_perc_60.xlsx",col_names = 'flux')
data2006<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2017_perc_60.xlsx",col_names = 'flux')
data2007<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2018_perc_60.xlsx",col_names = 'flux')
data2008<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2019_perc_60.xlsx",col_names = 'flux')
data2009<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2019_perc_60.xlsx",col_names = 'flux')
data2010<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2010_perc_60.xlsx",col_names = 'flux')
data2011<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2011_perc_60.xlsx",col_names = 'flux')
data2012<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2012_perc_60.xlsx",col_names = 'flux')
data2013<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2013_perc_60.xlsx",col_names = 'flux')
data2014<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2014_perc_60.xlsx",col_names = 'flux')
data2015<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2015_perc_60.xlsx",col_names = 'flux')
data2016<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2016_perc_60.xlsx",col_names = 'flux')
data2017<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2017_perc_60.xlsx",col_names = 'flux')
data2018<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2018_perc_60.xlsx",col_names = 'flux')
data2019<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2019_perc_60.xlsx",col_names = 'flux')


```

*Populating Data for Missing Years*

The data for 2007, 2008 and 2009 was missing. In order to impute this data, we took the mean and standard deviation of X-Ray intensities of surrounding years and generated a sequence of random numbers from the corresponding normal distribution. We generated 26280 random observations for 3 years missing hourly data. 

```{r echo=F, message=F}

xray_data_missing <-rbind(data2005,data2006,data2010)
mean_miss = mean(xray_data_missing$flux)
sd_miss = (xray_data_missing$flux)

data2007_2008_2009 = rnorm(26280, mean = mean_miss, sd = sd_miss)

xray_data<-rbind(data2000,data2001,data2002,data2003,data2004,data2005,data2006,
                 data2007_2008_2009,data2010,data2011,data2012,data2013,data2014,
                 data2015,data2016,data2017,data2018,data2019)
xray_data = xray_data[xray_data$flux != 0,]

cat("The total number of observation in time series is:", length(xray_data$flux)) 
cat("\nThe number of NAs in the dataset is:", sum(is.na(xray_data$flux))) 

```

*Dataset Characterisitcs*

Plotting Histogram and getting descriptive Statistics for the dataset,

```{r echo=F, message=F}

summary(xray_data)

hist(log(xray_data$flux), breaks = "freedman-diaconis")

```
Here we have plotted the historgram of natural log of X-ray intensities because it was hard to visualize very small values of raw data. We can see that the distribution is multi-modal. 

Now checking the distribution of Solar Flare vs Non-Solar Flare events. 

```{r echo = F, message = F}

convert_intensity_to_cat <- function(x) {
  cats <- factor(c('C', 'X'))
  y = rep(cats[1], length(x))
  
  
  for(i in 1:length(x)) {
    if(x[i] >= -5*log(10)) {
      y[i] = cats[2]
    } else {
      y[i] = cats[1]
    }
  }
  
  y
}

y_cat = convert_intensity_to_cat(log(xray_data$flux))

require(dplyr)
require(gridExtra)
piedf_train <- data.frame(y = y_cat) %>% group_by(y) %>% summarise(count=n())

p1<- ggplot(data = piedf_train, aes(x = "", y = count, fill = y)) + 
  geom_bar(stat = "identity", color='black') +  coord_polar("y") + scale_fill_brewer(palette="Blues") + theme_void()
p2 <- ggplot(data = data.frame(y = y_cat)) + geom_bar(aes(y = y)) + ylab('Category') + xlab("Counts") + theme_bw()

grid.arrange(p1, p2, nrow = 1)

```

It is evident that there are very few solar flare events. This observation is in line with the research and reality. 

*Checking for Stationarity*

Plotting the Xray data and log of Xray data to check for stationarity, 

```{r echo=F, message=F}


n <- nrow(xray_data)
seq <- 1:n
xray_data$seq <- seq


library(ggplot2)

ggplot(data=xray_data) + geom_line(aes(x = seq, y = flux)) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept= 10^-4, color = "red"))

ggplot(data=xray_data) + geom_line(aes(x = seq, y = log(flux))) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept=-9.51293, color = "red"))



```

Visually inspecting the time series $\{ y_1, y_2, \ldots, y_{141219} \}$ hints towards non-stationarity. 

Performing Augmented Dickey Fuller Test to check for stationarity,

```{r echo=F, message=F}

library(tseries)
adf.test(xray_data$flux)

library(tseries)
adf.test(log(xray_data$flux))

```

As per our research, the results of Augmented Dickey Fuller test can be slightly misleading. Hence double checking for presence of trend by fitting a Linear Regression model is a good idea,

```{r echo=F, message=F}

lm_fit <- lm(xray_data$flux~seq,xray_data)
summary(lm_fit)

```

The seq variable estimate indicate that there is a slight trend. Hence we will de-trend the data by taking the first difference. 


*Exploring the temporal structure*

Plotting the ACF and PACF plots of hourly data,

```{r echo=F, message=F}

acf(xray_data$flux)
pacf(xray_data$flux)

```

Takeaways: 

- Nothing decisive can be said about the MA component. Just by looking at the ACF, q seems be 2 or 3 because after that there is a sharp decline in ACF.

- The order of autoregressive component seems to be 1 or 3.

- There appear to be some seasonal patterns in the graphs but the nature of cyclical trends will be explored during spectrum analysis. 

*Spectrum Analysis*

```{r echo=FALSE, message=FALSE}

spectrum(xray_data$flux,spans=c(15,15,3))

```

Takeaways:

We are performing spectral analysis on hourly data. As per research, the solar flares are expected to happen every 11 years. This gives us a hint that using hourly data we will not be able to characterize different periodic components corresponding to solar activity. The spectrogram is expected to be multi-modal and the seasonality is expected to be at-least annual or every few years. 
This is also evident in the spectrogram above that as the frequency approaches zero the power approaches a very high number. There are no significant cyclical trends after every few hours. 

Although not useful to explore seasonal patterns but still this hourly data can be used to explore build-up to a solar flare. This problem will be investigated later in the project. 


## Daily Data

Now loading and analyzing the monthly data, 

```{r echo=F, message=F}

data1999_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data1999_perc_1440.xlsx",col_names = 'flux')
data2000_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2000_perc_1440.xlsx",col_names = 'flux')
data2001_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2001_perc_1440.xlsx",col_names = 'flux')
data2002_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2002_perc_1440.xlsx",col_names = 'flux')
data2003_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2003_perc_1440.xlsx",col_names = 'flux')
data2004_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2004_perc_1440.xlsx",col_names = 'flux')
data2005_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2005_perc_1440.xlsx",col_names = 'flux')
data2006_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2006_perc_1440.xlsx",col_names = 'flux')
data2007_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2007_perc_1440.xlsx",col_names = 'flux')
data2008_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2008_perc_1440.xlsx",col_names = 'flux')
data2009_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2009_perc_1440.xlsx",col_names = 'flux')
data2010_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2010_perc_1440.xlsx",col_names = 'flux')
data2011_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2011_perc_1440.xlsx",col_names = 'flux')
data2012_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2012_perc_1440.xlsx",col_names = 'flux')
data2013_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2013_perc_1440.xlsx",col_names = 'flux')
data2014_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2014_perc_1440.xlsx",col_names = 'flux')
data2015_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2015_perc_1440.xlsx",col_names = 'flux')
data2016_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2016_perc_1440.xlsx",col_names = 'flux')
data2017_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2017_perc_1440.xlsx",col_names = 'flux')
data2018_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2018_perc_1440.xlsx",col_names = 'flux')
data2019_day<- read_excel("C:/Users/gvozd/Desktop/University/R/Data sets/xray_data2019_perc_1440.xlsx",col_names = 'flux')


```



*Populating Data for Missing Years*

The data for 2007, 2008 and 2009 was missing. In order to impute this data, we took the mean and standard deviation of X-Ray intensities of surrounding years and generated a sequence of random numbers from the corresponding normal distribution. We generated 1095 random observations for 3 years missing daily data. 

```{r echo=F, message=F}

xray_data_day_missing <-rbind(data2005_day,data2006_day,data2010_day)
mean_miss = mean(xray_data_day_missing$flux)
sd_miss = (xray_data_day_missing$flux)

data2007_2008_2009 = rnorm(1095, mean = mean_miss, sd = sd_miss)

xray_data_day<-rbind(data1999_day,data2000_day,data2001_day,data2002_day,data2003_day,data2004_day, data2005_day,data2006_day,data2007_2008_2009, data2010_day, data2011_day,data2012_day,data2013_day,data2014_day,data2015_day,data2016_day,data2017_day
                     ,data2018_day,data2019_day)

xray_data_day = xray_data_day[xray_data_day$flux != 0,]

cat("The total number of observation in time series is:", length(xray_data_day$flux)) 
cat("\nThe number of NAs in the dataset is:", sum(is.na(xray_data_day$flux))) 

```

*Dataset Characterisitcs*

Plotting Histogram and getting descriptive Statistics for the dataset,

```{r echo=F, message=F}

summary(xray_data_day)

hist(log(xray_data_day$flux), breaks = "freedman-diaconis")

```

Like hourly data, the distribution of daily data appears to be multi-modal as well. 

Now checking the distribution of Solar Flare vs Non-Solar Flare events in daily data. 

```{r echo = F, message = F}

convert_intensity_to_cat <- function(x) {
  cats <- factor(c('C', 'X'))
  y = rep(cats[1], length(x))
  
  
  for(i in 1:length(x)) {
    if(x[i] >= -5*log(10)) {
      y[i] = cats[2]
    } else {
      y[i] = cats[1]
    }
  }
  
  y
}

y_cat = convert_intensity_to_cat(log(xray_data_day$flux))

require(dplyr)
require(gridExtra)
piedf_train <- data.frame(y = y_cat) %>% group_by(y) %>% summarise(count=n())

p1<- ggplot(data = piedf_train, aes(x = "", y = count, fill = y)) + 
  geom_bar(stat = "identity", color='black') +  coord_polar("y") + scale_fill_brewer(palette="Blues") + theme_void()
p2 <- ggplot(data = data.frame(y = y_cat)) + geom_bar(aes(y = y)) + ylab('Category') + xlab("Counts") + theme_bw()

grid.arrange(p1, p2, nrow = 1)

```

It is evident that like hourly data, in daily data as well there are very few solar flare events. 

*Checking for Stationarity*

Plotting the Xray daily data and log of Xray daily data to check for stationarity, 

```{r echo=F, message=F}

n <- nrow(xray_data_day)
seq <- 1:n
xray_data_day$seq <- seq


library(ggplot2)

ggplot(data=xray_data_day) + geom_line(aes(x = seq, y = flux)) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept= 10^-5, color = "red"))

ggplot(data=xray_data_day) + geom_line(aes(x = seq, y = log(flux))) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept=-5*log(10), color = "red"))



```

Visually inspecting the time series $\{ y_1, y_2, \ldots, y_{6274} \}$ hints towards non-stationarity. 

Performing Augmented Dickey Fuller Test to check for stationarity,

```{r echo=F, message=F}

library(tseries)
adf.test(xray_data_day$flux)

library(tseries)
adf.test(log(xray_data_day$flux))

```

As per our research, the results of Augmented Dickey Fuller test can be slightly misleading. Hence double checking for presence of trend by fitting a Linear Regression model is a good idea,


```{r echo=F, message=F}

lm_fit <- lm(xray_data_day$flux~seq,xray_data)
summary(lm_fit)

```

The seq variable estimate indicate that there is a slight trend. Hence we will de-trend the data by taking the first difference. 


*Exploring the temporal structure*

Plotting the ACF and PACF plots of hourly data,

```{r echo=F, message=F}

acf(xray_data_day$flux)
pacf(xray_data_day$flux)

```

Takeaways: 

- Nothing decisive can be said about the MA component.

- The order of autoregressive component seems to be 2.

- Seasonality is not very evident from the ACF and PACF plots. Conducting spectral analysis will tell us more about the seasonal components present in daily X-Ray data.  

*Spectrum Analysis*

```{r echo=FALSE, message=FALSE}

spec = spectrum(xray_data_day$flux,spans=c(15,15,3))

```

This is evident in the spectrogram above that as the frequency approaches zero the power approaches a very high number. 

In order to get a better view of different frequency components let us convert frequency to the period (in number of days) and plot it vs power. We will plot a subset of the frequencies to have a better view of different seasonal components in play. 


```{r echo=FALSE, message=FALSE}

spec<- cbind(1/spec$freq,spec$spec) 
spec <- as.data.frame(spec)
colnames(spec) <- c('freq','amp')

plot(spec[4:200,1],spec[4:200,2],type = "l")

```

Takeaways:

- There is a peak at roughly 1 year period. Meaning that there are hidden annual seasonal trends associated with x-ray intensities. 

- The power increases a lot as the number of years increases indicating that most of the seasonal trends follow a multi year cycle. This is in line with the fact that Solar Flare repeats after every 11 years. 

- Due to the granularity of the data and some constraints in the R spectrum function, the exact peaks can't be pin-pointed in the spectrum plot. 



## Research Questions

### Exploring seasonality


As mentioned in the previous sections, although the **PACF** gave us a somewhat decisive answer for our parameter, this was not the case with the **ACF**. Hence, in this section we will explore seasonality further. This time around, instead of looking at the whole data we will focus on different years separately and try find some common traits in the years where solar flares happened versus the years where no solar flares occurred. 


Our initial idea was the following:

We first split the Sun's state into 2 categories. Category 1 consists of periods when the sun is emitting lower intensity x-rays ("buzzing"). Naturally Category 2 refers to the periods when the sun produces higher intensity x-rays (blips) and hence generates solar flares.

We want to see if in the years (or parts of years) that fall into Category 1, we can observe shorter seasonal periods which are more significant that the longer ones. On the other hand, in the years (or parts of years) that fall into Category 2, we want to see whether the longer seasonal periods are more significant. For example, lets plot years 2003,2017 vs 2018,2019 (first two had a solar flare, the second two did not).
```{r}
plot(data2003_day$flux, ty="l")
plot(data2017_day$flux, ty="l")
plot(data2018_day$flux, ty="l")
plot(data2019_day$flux, ty="l")

```
In the first two graphs, we can see about 2-3 blips before the solar flare occurres. These blips are separated in intervals of approximately 50 up to 150 days. Therefore, we are expecting that frequencies of around 50 days and 100-150 days would be more significant that shorter ones.

On the other hand, if we look at the y-scale in the third and fourth graph we can see that these blips are insignificant and too small in magnitude. However, in years such as 2018,2019, we are expecting low intensity x-rays ("buzzing") and there is no seasonality corresponding to the larger build-up of blips before a solar flare happens.

In order to verify this claim, we plot the spectrogram of years: 2002,2004,2018,2019,2003,2006,2011,2017. Note that the first 4 years listed did not have solar flares where as the last 4 did.

```{r}

spec_02 = spectrum(data2002_day$flux)
spec_02<- cbind(1/spec_02$freq,spec_02$spec) 
spec_02 <- as.data.frame(spec_02)
colnames(spec_02) <- c('freq','amp')


spec_04 = spectrum(data2004_day$flux)
spec_04<- cbind(1/spec_04$freq,spec_04$spec) 
spec_04 <- as.data.frame(spec_04)
colnames(spec_04) <- c('freq','amp')


spec_18 = spectrum(data2018_day$flux)
spec_18<- cbind(1/spec_18$freq,spec_18$spec) 
spec_18 <- as.data.frame(spec_18)
colnames(spec_18) <- c('freq','amp')


spec_19 = spectrum(data2019_day$flux)
spec_19<- cbind(1/spec_19$freq,spec_19$spec) 
spec_19 <- as.data.frame(spec_19)
colnames(spec_19) <- c('freq','amp')


spec_03 = spectrum(data2003_day$flux)
spec_03<- cbind(1/spec_03$freq,spec_03$spec) 
spec_03 <- as.data.frame(spec_03)
colnames(spec_03) <- c('freq','amp')


spec_06 = spectrum(data2006_day$flux)
spec_06<- cbind(1/spec_06$freq,spec_06$spec) 
spec_06 <- as.data.frame(spec_06)
colnames(spec_06) <- c('freq','amp')


spec_11 = spectrum(data2011_day$flux)
spec_11<- cbind(1/spec_11$freq,spec_11$spec) 
spec_11 <- as.data.frame(spec_11)
colnames(spec_11) <- c('freq','amp')


spec_17 = spectrum(data2017_day$flux)
spec_17<- cbind(1/spec_17$freq,spec_17$spec) 
spec_17 <- as.data.frame(spec_17)
colnames(spec_17) <- c('freq','amp')





#par(mfrow=c(6,1))
plot(spec_02[1:200,1],spec_02[1:200,2],type = "l")
plot(spec_04[1:200,1],spec_04[1:200,2],type = "l")
plot(spec_18[1:200,1],spec_18[1:200,2],type = "l")
plot(spec_19[1:200,1],spec_19[1:200,2],type = "l")
plot(spec_03[1:200,1],spec_03[1:200,2],type = "l")
plot(spec_06[1:200,1],spec_06[1:200,2],type = "l")
plot(spec_11[1:200,1],spec_11[1:200,2],type = "l")
plot(spec_17[1:200,1],spec_17[1:200,2],type = "l")
```
In the first 4 graphs, we can see that frequencies which are less than 50 days are indeed significant. Contrary, graphs 5,6,7,8 have frequencies around 50+ days which are more significant than the shorter frequencies.

It is important to note that all years share some sort of seasonality which repeats every 100 days and goes up to around 200 days as well. Moreover, all years share very short frequencies as well, due to the low frequency Sun state which dominates in terms of duration. 

Takeaways:
 
- Pinpointing exact seasonal components of the X-ray flux data is currently not achievable. We are able to precisely pinpoint common seasonal components in the years in which solar flare occured versus the years where there were no solar flares. Whether these blips are connected to the frequencies we are seeing in the spectrographs is yet to be determined.

- One drawback from this approach is that the spectrographs assume that frequencies happen through out the year. So, if we find a frequency of 50 days to be relevant to the build-up blips we are seeing in the raw data; there is not clear answer when those 50 day-occurring blips start and when they lead to the "final" biggest blip which we define as a solar flare. 







### Fitting and Forecasting using an ARMA model

We will fit the model to the daily data and try to see whether our model is a good fit and helps us to forecast or not. As the data was not stationary, we will use the first order differenced data while fitting the model, 


DONE UP TO THIS POINT
##-------------##

```{r echo=F, message=F}

```


```{r echo=F, message=F}

require(lubridate)
require(dplyr)

d = 12

raw_xray2019 = read.csv('xray2019.csv', header = FALSE)
colnames(raw_xray2019) = c("date", "flux")
raw_xray2019[,1] =ymd_hms(raw_xray2019[,1])
raw_xray2019$day = day(raw_xray2019[,1])
raw_xray2019$month = month(raw_xray2019[,1])
raw_xray2019$everydh = hour(raw_xray2019[,1]) %/% d

summary(raw_xray2019)

xray_dh <- raw_xray2019 %>% group_by(day, month, everydh) %>% summarise(mflux = quantile(flux, .975))
xray_ts <- as.vector(unlist(xray_dh[,4]))


train_size = 718
ts_train <- log(xray_ts[1:train_size])
ts_test <- log(xray_ts[seq(train_size + 1, train_size +  14)])

hist(raw_xray2019$flux, breaks = 10000, xlim = c(0, 0.00001))


time_train_raw = seq(length(raw_xray2019[,4]))
xray_flux_raw <- as.vector(unlist(raw_xray2019$flux))
xray_train_df = data.frame(t = time_train_raw, x = xray_flux_raw)

plot(log(xray_ts),type="l")


library(tseries)
adf.test(log(xray_flux_raw))
acf(log(xray_flux_raw), lag.max = 100000)
pacf(log(xray_flux_raw), lag.max = 10)


raw_xray2019[raw_xray2019$flux > 0.00001]
which(raw_xray2019$flux > 0.00001)
raw_xray2019$flux[13650:13850]

```



```{r echo=F, message=F}

raw_xray2018 = read.csv(file="final.csv", header = FALSE)
raw_xray2018<-raw_xray2018[!(raw_xray2018$V2 == -99999),]
raw_xray2018 = raw_xray2018[-1,]
summary(raw_xray2018)

#raw_xray2018$V1

cor(raw_xray2018$V1, raw_xray2018$V2)

ggplot(data=xray_train_df) + geom_line(aes(x = t, y = x)) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept=-5*log(10), color = "orange")) + 
geom_hline(aes(yintercept=-4*log(10), color = "red")) + 
geom_hline(aes(yintercept=-6*log(10), color = "blue")) + 
scale_color_discrete(name = "Legend", labels = c("C", "M", "X")) +    
theme_bw()

```




```{r echo=F, message=F}

require(lubridate)
require(dplyr)

d = 12

raw_xray = read.csv('final_data.csv', header = FALSE)
raw_xray = raw_xray[-1,]
raw_xray<-raw_xray[!(raw_xray$V2 == -99999),]
n = nrow(raw_xray)
seq = 1:n
raw_xray$num <- seq 
#raw_xray = raw_xray[,-1]
raw_xray1 = raw_xray[,c(1,3)]

summary(raw_xray1)

hist(raw_xray, breaks = 10000, xlim = c(0, 0.000000001))

time_train_raw = seq(length(raw_xray2019[,4]))
xray_flux_raw <- as.vector(unlist(raw_xray2019$flux))
xray_train_df = data.frame(t = time_train_raw, x = xray_flux_raw)

plot(log(xray_ts),type="l")

library(tseries)
adf.test(log(xray_flux_raw))

acf(log(xray_flux_raw), lag.max = 100000)
pacf(log(xray_flux_raw), lag.max = 10)


raw_xray2019[raw_xray2019$flux > 0.00001]

which(raw_xray2019$flux > 0.00001)

raw_xray2019$flux[13650:13850]

```



```{r echo=F, message=F}
require(ggplot2)
require(gridExtra)

time_train = seq(length(ts_train))
time_test =   seq(train_size + 1, train_size + 14)

xray_train_df = data.frame(t = time_train, x = ts_train)
xray_test_df = data.frame(t = time_test, x = ts_test)
```


```{r echo=F, fig.align='center', fig.cap="Train Set X-ray fluxtime series in log scale"}
ggplot(data=xray_train_df) + geom_line(aes(x = t, y = x)) + ggtitle("X-ray Flux Activities in 2019 - Training Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept=-5*log(10), color = "orange")) + 
geom_hline(aes(yintercept=-4*log(10), color = "red")) + 
geom_hline(aes(yintercept=-6*log(10), color = "blue")) + 
scale_color_discrete(name = "Legend", labels = c("C", "M", "X")) +    
theme_bw()
```

```{r echo=F, fig.align='center', fig.cap = "Train Set X-ray intensities (in log scale) histogram"}
ggplot(data.frame(x = ts_train), aes(x= x)) + geom_histogram(color="black", fill="white", binwidth = 0.1) + theme_bw()
```


```{r echo=F, message=F}
convert_intensity_to_cat <- function(x) {
  cats <- factor(c('B', 'C', 'M', 'X'))
  y = rep(cats[1], length(x))
  
  
  for(i in 1:length(x)) {
    if(x[i] >= -4*log(10)) {
      y[i] = cats[4]
    } else if(x[i] >= -5*log(10)) {
      y[i] = cats[3]
    } else if(x[i] >= -6*log(10)) {
      y[i] = cats[2]
    } else {
      y[i] = cats[1]
    }
  }
  
  y
}

y_train = convert_intensity_to_cat(ts_train)
y_test = convert_intensity_to_cat(ts_test)
```

```{r echo=F,message=F, fig.align='center', fig.cap="Train Set Solar Flare Caterogy Distribution"}
piedf_train <- data.frame(y = y_train) %>% group_by(y) %>% summarise(count=n())

p1<- ggplot(data = piedf_train, aes(x = "", y = count, fill = y)) + 
  geom_bar(stat = "identity", color='black') +  coord_polar("y") + scale_fill_brewer(palette="Blues") + theme_void()
p2 <- ggplot(data = data.frame(y = y_train)) + geom_bar(aes(y = y)) + ylab('Category') + xlab("Counts") + theme_bw()

grid.arrange(p1, p2, nrow = 1)
```

# Research Methodology & Results

## Does data have predictive power ?

The first question is whether we can utilize the X-ray time series $y = (y_1, y_2, \ldots, y_n)$ to predict future solar events. If not then the time series is just white noise or a random walk distribution. To formally analyze, we perform a hypothesis test where $H_0:$ $y_1, y_2, \ldots, y_n$ are iid. This can be bone by ploting the acf of y. At significant level $\alpha = 5$\%, only 1/20 lag should be outside the acceptance region (blue dashed-line). We observe 4/20 lags outside, and therefor reject the null hypothesis that y are white noise and have confidence that it may be possible to predict future events.

```{r echo=F,message=F}
require(forecast)
ggAcf(ts_train, lag.max = 20) + ggtitle("X-ray Flux Train Set Acf") + theme_bw()
```

On the other hand, a different way to answer is to fit ARMA(p, q) models and see whether ARMA(0, 0) is favored in term of AIC scores. As we illustrate in the next section, models with $p > 0$ and $q > 0$ are indeed better than $p = q = 0$.

## Which model best fits the data ?

Our analysis implies that we can learn from the past data and $ARMA(p, q)$ models may be good candidates. Auto Regressive Moving Average (ARMA) is formally defined as $Y_n = \phi_1 Y_{n-1} + \ldots \phi_2Y_{n-p} + \mu + \psi_1 \epsilon_{n-1} + \ldots + \psi_q \epsilon_{n-q}$, or succinctly, $\phi(B)(Y_n - \mu) = \psi(B)\epsilon_n$ where B is the backshift operator,i.e., $Y_{n-1} = B Y_{n}$ and

\begin{align*}
\phi(B) &= 1 + \phi_1 B + \ldots \phi_p B^p \\
\psi(B) &= 1 + \psi_1 B + \ldots \psi_q B^q \\
\end{align*}

```{r echo=F,message=F,cache=T,warning=F}
aic_table <- function(data,P,Q) {
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
      table[p+1,q+1] <- arima(data,order=c(p,0,q))$aic
    }
  }
  dimnames(table) <- list(paste("<b> AR",0:P,"<b>", sep=""),paste("<b> MA",0:Q,"<b>",sep=""))
  table
}

require(knitr)
aic_table <- aic_table(ts_train,5,5)
kable(aic_table, digits = 2)
```


To select parameters (p, q), we fit different models with $p,q \in \{1,2,3,4,5\}$ then pick the one with lowest AIC. One thing to note from the below table is that AIC values seems not reliable because of some big jumps of AIC even when number of parameters changes by only 1. Under that scenario, theoretically, AIC score can only move up or down by 2. As the majority of values in the table are in range 2220-2233, we pick only models within this range. The 4 candidates are ARMA(0, 3), ARMA(0, 4), ARMA(1, 3) and ARMA(1, 4) where AIC is 2020.55, 2022.55, 2022.55 and 2020.37 respectively. Inspecting the coefficients, we observe that the intercept is the same for all models but standard deviation is largest for ARMA(0, 4). In addition, ARMA(1,4)'s coefficients of AR1, MA1, MA2 and MA4 are also biggest. It implies that ARMA(1, 4) indeed best fits the X-ray flux train time series.

```{r echo=F,message=F,cache=T}
arma.table <- function(data, R, orders){
  table <- matrix(NA, R, 7)
  for(r in 1:R){
    arma.tmp <- arima(data, order = orders[[r]])
    table[r, 1] <- round(arma.tmp$coef["intercept"],3)
    table[r, 2] <- round(sqrt(arma.tmp$var.coef["intercept", "intercept"]),3)
    table[r, 3] <- round(arma.tmp$coef["ar1"],3)
    if(is.na(table[r, 3])) table[r, 3] <- "--"
    table[r, 4] <- round(arma.tmp$coef["ma1"],3)
    table[r, 5] <- round(arma.tmp$coef["ma2"],3)
    table[r, 6] <- round(arma.tmp$coef["ma3"],3)
    table[r, 7] <- round(arma.tmp$coef["ma4"],3)
    if(is.na(table[r, 7])) table[r, 7] <- "--"
}
  dimnames(table) <- list(c("<b> ARMA(0, 3)", "<b> ARMA(0, 4)", "<b> ARMA(1, 3)", "<b> ARMA(1, 4)"), c("Intercept", "SE(Intercept)", "AR Coef.", "MA 1 Coef.", "MA 2 Coef.", "MA 3 Coef.", "MA 4 Coef."))
  table
}

temp.armas <- arma.table(ts_train, R = 4, orders = list(c(0,0,3), c(0,0,4), c(1,0,3), c(1,0,4)))
require(knitr)
kable(temp.armas)
```

### 95\% CI for ARMA(1,4)

```{r echo=F}
arma14 <- Arima(ts_train, order=c(1,0,4))
```

As we decided to proceed with ARMA(1,4), the following is the 95% confidence interval for the models' coefficients.

```{r echo=F, message=F, fig.align='center',fig.cap='95% CI for ARMA(1,4) Coefficients'}
arima14_ci_tab = matrix(NA, nrow = 6, ncol = 2)
arima14_ci_tab[1,1:2] = -12.6808 + c(-1.96,1.96) * 0.0953
arima14_ci_tab[2,1:2] = c(0.88, 1.008484)
arima14_ci_tab[3,1:2] = -0.7305 + c(-1.96,1.96) * 0.0378 
arima14_ci_tab[4,1:2] = -0.2923 + c(-1.96,1.96) * 0.0464
arima14_ci_tab[5,1:2] = -0.0897 + c(-1.96,1.96) * 0.0467
arima14_ci_tab[6,1:2] = 0.1315 + c(-1.96,1.96) * 0.0360
dimnames(arima14_ci_tab) <- list(c("<b> Intercept<b>","<b> AR1<b>","<b> MA1<b>","<b>MA2<b>","<b> MA3<b>","<b> MA4<b>"), c("<b> 2.5%<b>","97.5%"))
require(knitr)
kable(arima14_ci_tab)
```

The reported AR1's 95% CI in the table is produced by the profile log likelihood. Since AR1 parameter is the one component that actually involves the past data, we want to be more precise. 

The Fisher approximation CI is $0.9930 + c(-1.96,1.96) * 0.0079 = c(0.977516, 1.008484)$ and we claim it's much narrower than the true 95% CI. This can be seen from plotting out the profile log likelihood in the below. In addition, a simulation was carried out to verify that the profile log likehood curve's shape. Because the the curve around the MLE (the highest peak) is very sharp, an approximate quadratic curve at the MLE would a result a much narrower CI than the true interval.


```{r echo=F,message=F,warning=F,cache=T}
K <- 500
set.seed(1997)
ar1 <- seq(from=0.4,to= 0.999,length=K)

profile_loglik <- rep(NA,K)

for(k in 1:K){
  profile_loglik[k] <- logLik(arima(ts_train,order=c(1,0,4), fixed=c(ar1[k],NA,NA,NA,NA,NA)))
}
```

```{r echo=F,warning=F,message=F,cache=T}
set.seed(1)
J <- 1000

params <- coef(arma14)
ar <- params[grep("^ar",names(params))]
ma <- params[grep("^ma",names(params))]
intercept <- params["intercept"]
sigma <- sqrt(arma14$sigma2)
theta <- matrix(NA,nrow=J,ncol=length(params),
dimnames=list(NULL,names(params)))

for(j in 1:J){
  Y_j <- arima.sim(list(ar=ar,ma=ma),n=length(ts_train), sd=sigma) + intercept
  theta[j,] <- coef(arima(Y_j,order=c(1,0,4)))
}
```

```{r echo=F, fig.align='center',fig.cap="AR by Profile Likelihood"}
plot(profile_loglik~ar1,ty="l")
abline(h=(max(profile_loglik) -1.92), col='red')
```

```{r echo=F, fig.align='center',fig.cap="AR Distribution by Simulation"}
ggplot(data.frame(x = theta[,"ar1"]), aes(x= x)) + geom_histogram(color="black", fill="white", binwidth = 0.025) + theme_bw()
```

### ARMA(1, 4) GoF

To evaluate ARMA(1, 4) Goodness of Fit, we observe that the roots MA polynomial $\psi(x)$ are outside of a unit circle and means that the model is causal. However, the root of AR polynomial $\phi(x)$ is $r_1 = 1.007095$ barely outside of the unit circle and it's possible that ARMA(1, 4) is non-invertible. The following plot is to visualize the inverse roots of ARMA polys. As such, for invertible and causal models, the inverse roots should be inside the unit circle.


```{r echo=F,message=F,fig.align='center',fig.cap="Plot of Inverse ARMA Roots"}
require(forecast)
autoplot(arma14)
```

Given that ARMA(1,4) nearly on the verge of invertibility, we need to check the residuals. While there are no obivious residual patterns, residual is normal but not for extreme values and the acf also indicates some correlation. These are signs of the ill-fitness of ARMA(1,4). Moreover, we can also plot out the fitted data and overlay with the original time series. As observed from this figure, the original y is the gray dashed line and the fitted values are red points and lines. The fitted time series doesn't seem to be able to capture the peaks correctly. These are signs of illness of fit of ARMA(1,4) over this data. As such, in the next section, we want to assess the model's predictive power on a reserved test set. 

```{r echo=F, fig.align='center',fig.cap='ARMA(1,4) Residual Plot'}
par(mfrow=c(2,2))
plot(arma14$resid, ylab = "Residuals [ARMA(1,4)]")
qqnorm(arma14$residuals, main = "QQ-Plot: Residuals of ARMA(1,4)")
qqline(arma14$residuals)
acf(arma14$residuals, main = "ACF: Residuals of ARMA(1,4)")
```

```{r echo=F,fig.align='center',fig.cap='ARMA(1,4) Fitted Time Series vs X-ray Train Set'}
ggplot() + geom_point(data = data.frame(x = 1: length(ts_train), y = fitted(arma14)), aes(x, y), color='red') +  geom_line(data = data.frame(x = 1: length(ts_train), y = fitted(arma14)), aes(x, y), color='red') + geom_line(data = data.frame(x = 1: length(ts_train), y = ts_train), aes(x, y), color='gray', linetype='dashed') + scale_y_continuous(expand = c(0,0)) + theme_bw()
```


## Is there seasonal effect ?

Many solar activities are periodic. Thus, we're interested to study whether the X-ray time series exhibit any periodic behaviors. To do so, we examine the data in frequency domain and its periodogram. In the following, the unsmoothed periodgram doesn't have any obvious peaks. On the other hand, the smoothed periodogram and periodogram estimated by AR(p) have the dominant frequency about $f =.125$ or period = 8 observations = 4 days.

```{r echo=F,message=F}
par(mfrow=c(1,2))
spectrum(ts_train, main="Unsmoothed x-ray flux periodogram")
smth_est = spectrum(ts_train, span = c(30,30))
abline(v=smth_est$freq[which.max(smth_est$spec)], lty="dotted", col = 'red')
print(paste0("Smoothed peridogram peak is at ", smth_est$freq[which.max(smth_est$spec)]))
```

```{r echo=F,message=F}
aic_est = spectrum(ts_train, method = "ar", main = "Spectrum estimated via AR(p) picked by AIC")
abline(v=aic_est$freq[which.max(aic_est$spec)], lty="dotted", col = 'red')
print(paste0("AR(p) by AIC peridogram peak is at ", aic_est$freq[which.max(aic_est$spec)]))
```

Another way to look for periodic behaviors is to decompose the time series into trend, noise and cycle by using loess smoothing function with different span parameters for high and low frequency. Looking at the cycle, we do see a peak every 8 observations.
 
```{r echo=F,fig.align='center'}
ts = ts_train
trend <- ts(loess(ts~time_train,span=0.5)$fitted,
start=1,frequency=12)
noise <- ts(ts - loess(ts~time_train,span=0.1)$fitted,
start=1,frequency=12)
cycles <- ts - trend - noise
plot(ts.union(ts, trend,noise,cycles),
main="Decomposition of X-ray flux as trend + noise + cycles")
```

### SARIMA for seasonality

Since  there is a seasonal effect every 8 observations, we consider ARIMA(p, q, P, Q, s). The SARIMA model is defined as $\phi_p(B) \Phi_P(B^{12})\left( ((1 -B)^d(1 - B^{12})^D)Y_n - \mu \right) = \psi(B) \Psi(B^{12}) \epsilon_n$ where the coefficients of $\Phi(B^{12}), \Psi(B^{12})$ are the seasonal parameters.

As the X-ray time series has no obvious trend, d = D = 0. We choose p = 1, q = 4 and s = 8 from our analysis . Similar to last section, an AIC table can generated for the seasonal P and Q. The table again has many big jumps. Moreover, when including seasonal parameters, there's a big risk of overfitting data and the Occam's Razor principle tells us to select the simplest possible models. Ideally, we would like to stick to the upper left of the AIC table as much possible. Because the AIC scores have huge gaps after AR2-MA0 and AR0-MA2 and across the sub-table starting at AR1-MA1, we ignore these models and pick P = 2 and Q = 0 which is the simplest model with lowest AIC. 

```{r echo=F,message=F, cache=T}
require(astsa)
set.seed(0)
sea_aic_table <- function(data,i,j, P, Q, s) {
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
      table[p+1,q+1] <- arima(data,order=c(i,0,j), 
                              seasonal = list(order= c(p,0,q),
                              period=s))$aic
    }
  }
  dimnames(table) <- list(paste("<b> AR",0:P,"<b>", sep=""),paste("<b> MA",0:Q,"<b>",sep=""))
  table
}

sea_aic_table <- sea_aic_table(ts_train,1,4,4,4,8)
require(knitr)
kable(sea_aic_table, digits = 2)
```

### SARIMA(1,4,2,0,8) GoF

We go through the same routine as in the last section to produce 95\% CI for model parameters and evaluate SARIMA Goodness of Fit. SARIMA(1,4,2,0,8) are invertible and causal but residuals seem to be correlated and the fitted values still miss the peaks of the original time series.

```{r echo=F,message=F}
sarima20 <- Arima(ts_train,order=c(1,0,4), 
                              seasonal = list(order= c(2,0,0),
                              period=8))
```

```{r echo=F, message=F, fig.align='center',fig.cap='95% CI SARIMA Coefficients'}
sarima20_ci_tab = matrix(NA, nrow = 8, ncol = 2)

sarima20_ci_tab[1,1:2] = -12.6492 + c(-1.96,1.96) * 0.0501
sarima20_ci_tab[2,1:2] = 0.5084  + c(-1.96,1.96) * 0.4739 
sarima20_ci_tab[3,1:2] = -0.2384  + c(-1.96,1.96) * 0.4739 
sarima20_ci_tab[4,1:2] = -0.1509 + c(-1.96,1.96) * 0.1332
sarima20_ci_tab[5,1:2] = -0.1051 + c(-1.96,1.96) * 0.0391
sarima20_ci_tab[6,1:2] = 0.0773 + c(-1.96,1.96) * 0.0647
sarima20_ci_tab[7,1:2] = 0.0734 + c(-1.96,1.96) * 0.0377
sarima20_ci_tab[8,1:2] = 0.0674  + c(-1.96,1.96) * 0.0382
dimnames(sarima20_ci_tab) <- list(c("<b> Intercept<b>","<b> AR1<b>","<b> MA1<b>","<b>MA2<b>","<b> MA3<b>","<b> MA4<b>","<b> SAR1<b>","<b> SAR2<b>"), c("<b> 2.5%<b>","97.5%"))
require(knitr)
kable(sarima20_ci_tab)
```


```{r echo=F,message=F,fig.align='center', fig.cap="Plot of SARIMA Inverse Roots"}
autoplot(sarima20)
```

```{r echo=F,fig.align='center',fig.cap='SARIMA(1,4,2,0,8) Residual Plot'}
par(mfrow=c(2,2))
plot(sarima20$resid, ylab = "Residuals [SARIMA(2,0)]")
qqnorm(sarima20$residuals, main = "QQ-Plot: Residuals of ARMA(2,0)")
qqline(sarima20$residuals)
acf(sarima20$residuals, main = "ACF: Residuals of SAIRMA(2,0)")
```

```{r echo=F, fig.align='center',fig.cap="SARMIA(2,0) fitted values"}
ggplot() + geom_point(data = data.frame(x = 1: length(ts_train), y = fitted(sarima20)), aes(x, y), color='blue') +  geom_line(data = data.frame(x = 1: length(ts_train), y = fitted(sarima20)), aes(x, y), color='blue') + geom_line(data = data.frame(x = 1: length(ts_train), y = ts_train), aes(x, y), color='gray',linetype='dashed') + scale_y_continuous(expand = c(0,0)) + theme_bw()
```

## Regression against Sunspot Count

The geophysical properties of sunspots and solar flares are intimately connected and thus we want to study whether the daily sunspot counts help improve the solar flare prediction.

### Sunspot Count Data

We downloaded the daily sunspot number from this source: http://www.sidc.be/silso/DATA/EISN/EISN_current.csv. There are two things to note about this raw data. 2019 is a leap year yet the sunspot data doesn't include 02/29, so we added the missing data by simply taking the average of counts in 02/28 and 03/01. In addition, since our X-ray time series has one observation for every 12-hours or 0.5 days, we create the sunspot count every 12-hour time series by replicating one daily-count into two identical halfday-counts.

Moreover, the sunspot time series seems to have a trend which can be seen by employing a loess function with low frequency span. As such, we need to detrend by the Hodrick-Prescott (HP) Filter. HP filter of $(x_1, \ldots, x_n)$ and the time series $(s^*_1, \ldots, s^*_n)$ such that:

$$s^{*}_{1,n} = \text{arg min}_{s} \sum_{i=1}^n (x_i - s_i)^2 + \lambda\sum_{i=1}^n (s_{i+1} - 2s_i + s_{i-1})^2$$

Lastly, we also split the sunspot time series into a train set and a test set. The reserved test set will be discussed in the section about model performance.


```{r echo=F, message=F}
require(mFilter)

sunspots = read.csv('sunspots.csv', sep = ';')
sunspots_2019 = sunspots[sunspots$Year == 2019,]
sunspots_2019 = rbind(sunspots_2019, c(2019,2,29,2019.162, 0, 0.0, 34, 1))
sunspots_2019 = sunspots_2019[order(sunspots_2019$Time),]

sunspot_count_daily = sunspots_2019$Total
sunspot_count_dh = rep(sunspots_2019$Total, each = 24 %/% d)

sunspot_daily_hp = hpfilter(sunspot_count_daily, freq=100,type="lambda",drift=F)$cycle
sunspot_dh_hp = hpfilter(sunspot_count_dh, freq=100,type="lambda",drift=F)$cycle

sunspot_count_train = sunspot_count_dh[1:length(ts_train)]
sunspot_count_test = sunspot_count_dh[(length(ts_train) + 1): (length(ts_train) + length(ts_test))]

sunspot_hp_train = sunspot_dh_hp[1:length(ts_train)]
sunspot_hp_test = sunspot_dh_hp[(length(ts_train) + 1): (length(ts_train) + length(ts_test))]
```

```{r echo=F,fig.align='center'}
ts = sunspot_count_daily
trend <- ts(loess(ts~seq(1:length(sunspot_count_daily)),span=0.5)$fitted,
start=1,frequency=12)
plot(ts.union(ts, trend),
main="Trend in the sunspot train set")
```

```{r echo=F, message=F, fig.align='center', fig.cap='Sunspot Count Data'}
p1 <- ggplot(data= data.frame(t=1:length(sunspot_count_daily), x=sunspot_count_daily)
) + geom_line(aes(x = t, y = x)) + ggtitle("2019 daily Sunspot Count") + xlab("Time") + ylab("Number of Sunspots") + theme_bw()

p2 <- ggplot(data= data.frame(t=1:length(sunspot_count_dh), x=sunspot_count_dh)
) + geom_line(aes(x = t, y = x)) + ggtitle("2019 sunspot Count every-12h") + xlab("Time") + ylab("Number of Sunspots") + theme_bw()

p3 <- ggplot(data= data.frame(t=1:length(sunspot_dh_hp), x=sunspot_dh_hp)
) + geom_line(aes(x = t, y = x)) + ggtitle("HP Filtered daily count") + xlab("Time") + ylab("Number of Sunspots") + theme_bw()

p4 <- ggplot(data= data.frame(t=1:length(sunspot_dh_hp), x=sunspot_dh_hp)
) + geom_line(aes(x = t, y = x)) + ggtitle("HP Filtered  12h-count") + xlab("Time") + ylab("Number of Sunspots") + theme_bw()

grid.arrange(p1, p2, p3, p4, nrow = 2)
```

### Regression with Sunspot Count

If it's possible to predict the X-ray flux intensities from the number of sunspots, there should be correlation between the two time series. As noted from cross correlation plot, at significant level $\alpha = 5$%, we expect only 1/20 outside the acceptance reason. We noticed 2 lags outside and conclude that the X-ray and sunspot time series are correlated.

```{r echo=F, message=F}
ggCcf(ts_train, sunspot_hp_train, lag.max = 20) + ggtitle("CCF for hourly time series") + theme_bw()
```

Next, we select p and q of the ARIMA(p,q) regressing against sunspot count by constructing AIC, report 95% CI for relevant parameters and evaluate its goodness of fit as before. X-ray ARMA(1,4) regressing model has the most reasonable AIC. Unfortunately, the regression ARMA(1,4) model has the same problem like ARMA(1,4) and SARIMA(1,4,2,0,8). It could not capture the peaks of the flare intensities

```{r echo=F, message=F, warning=F,cache=T, fig.align='center', fig.cap='ARIMA Regression AIC table'}
cross_aic_table <- function(data,P,Q,xreg=NULL) {
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
      table[p+1,q+1] <- arima(data,order=c(p,0,q),xreg=xreg)$aic
    }
  }
  dimnames(table) <- list(paste("<b>AR",0:P,"<b>", sep=""), paste("<b>MA",0:Q, "<b>",sep=""))
  table
}

cross_hp_table <- cross_aic_table(ts_train, 4,4, xreg=sunspot_hp_train)
require(knitr)
kable(cross_hp_table,digits=2)
```


```{r echo=F}
hp_reg = Arima(ts_train, order = c(1, 0, 4), xreg = sunspot_hp_train)
```

```{r echo=F, message=F, fig.align='center',fig.cap='95% CI Regression'}
hpreg_ci_tab = matrix(NA, nrow = 7, ncol = 2)

hpreg_ci_tab[1,1:2] = -12.6819 + c(-1.96,1.96) * 0.0080 
hpreg_ci_tab[2,1:2] = 0.9928  + c(-1.96,1.96) * 0.0379
hpreg_ci_tab[3,1:2] = -0.7290  + c(-1.96,1.96) * 0.0463
hpreg_ci_tab[4,1:2] = -0.2937 + c(-1.96,1.96) * 0.0466 
hpreg_ci_tab[5,1:2] = -0.0901 + c(-1.96,1.96) * 0.0360 
hpreg_ci_tab[6,1:2] = 0.1319 + c(-1.96,1.96) * 0.0954
hpreg_ci_tab[7,1:2] = 0.0109 + c(-1.96,1.96) * 0.0158
dimnames(hpreg_ci_tab) <- list(c("<b> Intercept<b>","<b> AR1<b>","<b> MA1<b>","<b>MA2<b>","<b> MA3<b>","<b> MA4<b>","<b> Xreg<b>"), c("<b> 2.5%<b>","97.5%"))
require(knitr)
kable(hpreg_ci_tab)
```

```{r echo=F, fig.align='center',fig.cap='Plot of ARMA Regression Inverse Roots'}
autoplot(hp_reg)
```

```{r echo=F, fig.align='center',fig.cap='ARMA Regression Residual Plot'}
par(mfrow=c(2,2))
plot(hp_reg$resid, ylab = "Residuals ARMA(1,4) Sunspot Regression")
qqnorm(hp_reg$residuals, main = "QQ-Plot: Residuals of ARMA(1,4) Sunspot Regression")
qqline(hp_reg$residuals)
acf(hp_reg$residuals, main = "ACF: Residuals of ARMA(1,4) Sunspot Regression")
```

```{r echo=F, fig.align='center',fig.cap='Regression ARIMA Fitted Values'}
ggplot() + geom_point(data = data.frame(x = 1: length(ts_train), y = fitted(hp_reg)), aes(x, y), color='orange') +  geom_line(data = data.frame(x = 1: length(ts_train), y = fitted(hp_reg)), aes(x, y), color='orange') + geom_line(data = data.frame(x = 1: length(ts_train), y = ts_train), aes(x, y), color='gray', linetype='dashed') + scale_y_continuous(expand = c(0,0)) + theme_bw()
```


## Section Conclusion 

In summary, we conclude the following from our research investigation:

1. The data indeed possess predictive power. This is supported by inspecting the autocorrelation of the time series which revealed significant correlation within the time series. It can also be seen by the fact that the AIC value of ARMA(0, 0) is unfavorable compared to ARMA($p \ne 0, q \ne 0$) models.

2. Among ARMA(p,q), we find that ARMA(1, 4) fits the data best in term of AIC. In addition,  a seasonal effect every 8 observations can be observed from a smoothed periodogram. SARIMA(1,4,2,0,8) is selected by AIC to model seasonality. However, we remark that the SARIMA model may be overparameterized and we cautiously proceed with both ARMA and SARIMA in the next section.

3. We also create the sunspot count every half-day time series and study whether it helps with predicting X-ray intensities. The cross correlation is significant between the two time series, X-ray flux and sunspot count. Following a similar routine, Regression ARMA(1, 4) is chosen to be the most suitable regression model.

4. While each of the three models seems acceptable in term of the polynomial roots and residual diagnosis, their fitted values miss the high peaks of original time series data. We suspect it is because the sharp increase in intensity during a solar flare can not be captured adequately with linear relationships among past observations. The linear relationships are however the cornerstone of ARIMA models. 

In the next section, we assess the fitted models' actual predictive power over the reserved test dataset.

# Model Predictive Power Assessment

## Test Set Data

As mentioned in the Data section, we reserved a test set for this section. The test set size is 14 half-day data points. The reason for a relatively small test set is that state of the art solar flare models in the literature can not predict accurately more than a few days. The test set is also selected so that it includes a flare event of class M. The X-ray flux time series and flare category plots are shown in the below.

```{r echo=F,message=F}
ggplot(data=xray_test_df) + geom_line(aes(x = t, y = x)) + ggtitle("X-ray Flux Activities in 2019 - Test Set") + xlab("Time") + ylab("Intensties") + geom_hline(aes(yintercept=-4*log(10), color = "Orange")) +
geom_hline(aes(yintercept=-5*log(10), color = "Red")) + 
geom_hline(aes(yintercept=-6*log(10), color = "Blue")) +   
scale_color_discrete(name = "Legend", labels = c("C", "M", "X")) +  
theme_bw()  
```

```{r echo=F, fig.align='center', fig.cap='Test Set Flare Cateogry Distribution'}
piedf_test <- data.frame(y = y_test) %>% group_by(y) %>% summarise(count=n())
p1 <- ggplot(data = piedf_test, aes(x = "", y = count, fill = y)) + 
  geom_bar(stat = "identity", color='black') +  coord_polar("y") + scale_fill_brewer(palette="Blues") + theme_void()
p2 <- ggplot(data = data.frame(y = y_test)) + geom_bar(aes(y = y)) + ylab('Category') + xlab("Counts") + theme_bw()
grid.arrange(p1, p2, nrow = 1)
```

## Model Performance

```{r echo=F}
whitenoise_fit = Arima(ts_train, order = c(0,0,0))
```

Given the fiited models from previous sections, in R, we can use forecast package to generate the point estimate and 95% CI prediction for the next 14 lags $\{y_1^*, \ldots, y_{14}^*\}$. The below 4 plots show the forecast of fitted White Noise, ARMA(1, 4), SARIMA(1, 4, 2, 0, 8) and Sunspot Regression ARMA(1, 4) in black and the ground truth test data series in red. Visually, the predicted point estimates don't seem to track the test set time series well.

```{r echo=F}
wn_pred <- forecast(whitenoise_fit, h =  length(ts_test))
arma14_pred <- forecast(arma14,  h = length(ts_test))
sarima20_pred <- forecast(sarima20, h = length(ts_test))
hp_pred <- forecast(hp_reg, h=14, xreg = sunspot_hp_test)
```

```{r echo=F, fig.align='center', fig.cap='Mean Estimated and 95% CI Forecast (black) with X-ray true test (red)'}
p1 <- ggplot(data=data.frame(mean = wn_pred$mean, upper = wn_pred$upper[,2], lower = wn_pred$lower[,2], t = seq(1:length(ts_test)))) + 
    geom_line(aes(x = t, y = mean)) +
    geom_ribbon(aes(x= t, ymin=lower,ymax=upper),alpha=0.3) +
    geom_line(data = data.frame(y = ts_test, x =  seq(1:length(ts_test))), aes(x,y), color='red') +  xlab("Time") + ylab("Log Intensity") + scale_y_continuous(expand = c(0,0)) + ggtitle('White Noise') + theme_bw() 

p2 <- ggplot(data=data.frame(mean = arma14_pred$mean, upper = arma14_pred$upper[,2], lower = arma14_pred$lower[,2], t = seq(1:length(ts_test)))) + 
    geom_line(aes(x = t, y = mean)) +
    geom_ribbon(aes(x= t, ymin=lower,ymax=upper),alpha=0.3) +
    geom_line(data = data.frame(y = ts_test, x =  seq(1:length(ts_test))), aes(x,y), color='red')+ scale_y_continuous(expand = c(0,0)) + xlab("Time") + ylab("Log Intensity") + ggtitle('ARMA(1,4)') + theme_bw()

p3 <- ggplot(data=data.frame(mean = sarima20_pred$mean, upper = sarima20_pred$upper[,2], lower = sarima20_pred$lower[,2], t = seq(1:length(ts_test)))) + 
    geom_line(aes(x = t, y = mean)) +
    geom_ribbon(aes(x= t, ymin=lower,ymax=upper),alpha=0.3) +
    geom_line(data = data.frame(y = ts_test, x =  seq(1:length(ts_test))), aes(x,y), color='red') +  ggtitle('SARIMA(2,0)') + scale_y_continuous(expand = c(0,0)) + xlab("Time") + ylab("Log Intensity")  + theme_bw()

p4 <- ggplot(data=data.frame(mean = hp_pred$mean, upper = hp_pred$upper[,2], lower = hp_pred$lower[,2], t = seq(1:length(ts_test)))) + 
    geom_line(aes(x = t, y = mean)) +
    geom_ribbon(aes(x= t, ymin=lower,ymax=upper),alpha=0.3) +
    geom_line(data = data.frame(y = ts_test, x =  seq(1:length(ts_test))), aes(x,y), color='red') + ggtitle('Regression ARMA') +  xlab("Time") + ylab("Log Intensity") + scale_y_continuous(expand = c(0,0)) + theme_bw() 


grid.arrange(p1, p2, p3, p4, nrow = 2,ncol = 2)
```


A more quantitative way to assess model performance is the root mean squared error (RMSE). Given the true intensities $\{y^0_1, \ldots, y^0_n\}$ and the predicted $\{y_1^*, \ldots, y^*_n \}$, RMSE is defined as 

$$\text{rmse} = \sqrt{\cfrac{1}{n}\cdot \sum_{i=1}^n(y^0_i- y^*_i)^2}$$

```{r echo=F}

table = matrix(NA, nrow = 1, ncol = 4)

wn_pred <- predict(whitenoise_fit, length(ts_test))$pred
arma14_pred <- predict(arma14, length(ts_test))$pred
sarima20_pred <- predict(sarima20, length(ts_test))$pred
hp_pred <- forecast(hp_reg, h=14, xreg = sunspot_hp_test)$mean

table[1,1] = sqrt(mean((ts_test - wn_pred)^2))
table[1,2] = sqrt(mean((ts_test - arma14_pred)^2))
table[1,3] = sqrt(mean((ts_test - sarima20_pred)^2))
table[1,4] = sqrt(mean((ts_test - hp_pred)^2))

dimnames(table) <- list(c("<b>rmse<b>"), c("White Nose","ARMA(1,4)","SARIMA(2,0)", "Reg ARMA(1,4)"))
kable(table)
```

From the table, SARIMA(1,4,2,0,8) has the biggest RMSE, worse than white noise. This could be due to overfitting. ARMA(1,4) has the lowest rmse and surprisingly regression against number of sunspot counts doesn't improve the error though still do better than white noise.

RMSE is a good metric. Nevertheless, it doesn't offer much room for interpretation. A more intuitive way to judge the performance is to convert the raw forecast intensities into flare categories and calculate the prediction accuracy. Let $\{z^0_1, \ldots, z^0_n\}$ be true category labels and $\{z^*_1, \ldots, z^*_n$\} predicted ones. Accuracy score = $\cfrac{1}{n}\cdot\sum_{i=1}^n \mathbb{1}(z^0_i = z^*_i)$.

```{r echo=F}
y_win_pred = convert_intensity_to_cat(wn_pred)
y_arima14_pred = convert_intensity_to_cat(arma14_pred)
y_sarima20_pred = convert_intensity_to_cat(sarima20_pred)
y_hp_pred = convert_intensity_to_cat(hp_pred)

acc_table = matrix(NA, nrow = 1, ncol = 4)
acc_table[1,1]= sum(y_win_pred == y_test) / length(y_test)
acc_table[1,2] = sum(y_arima14_pred == y_test) / length(y_test)
acc_table[1,3] = sum(y_sarima20_pred == y_test) / length(y_test)
acc_table[1,4]= sum(y_hp_pred == y_test) / length(y_test)


dimnames(acc_table) <- list(c("<b>Accuracy Score<b>"), c("White Nose","ARMA(1,4)","SARIMA(2,0)", "Reg ARMA(1,4"))
kable(acc_table)
```

At the first look, since there are 3 categories (B, C, M) in the test set, an accuracy score of 57.14 % seems like a fine score. However, by noticing that majority of the test set is C class, and so this score might not be that good. We see an obvious problems by printing out the prediction vector of all models. They all just predicted 'C'.

```{r echo=F}
y_win_pred = convert_intensity_to_cat(wn_pred)
y_arima14_pred = convert_intensity_to_cat(arma14_pred)
y_sarima20_pred = convert_intensity_to_cat(sarima20_pred)
y_hp_pred = convert_intensity_to_cat(hp_pred)

lab_table = matrix(NA, nrow = 4, ncol = 14)
lab_table[1,]= as.character(y_win_pred)
lab_table[2,] = as.character(y_arima14_pred)
lab_table[3,] = as.character(y_sarima20_pred)
lab_table[4,]= as.character(y_hp_pred)


dimnames(lab_table) <- list(c("White Nose","ARMA(1,4)","SARIMA(2,0)", "Reg ARMA(1,4"), paste(1:14))
kable(lab_table)
```

This problem can be quantitatively formulated in term of the Sensitivity, Specificity and F1 scores which are defined in the following link https://en.wikipedia.org/wiki/F-score. A detailed analysis of these scores will not add much value to the current discussion and we shall only remark the intuitive conclusion from this table that by completely focusing on one metric (Sensitivity/ Specificity) and ignoring the other, the overall balanced performance (f1-score) suffers.

```{r echo=F,message=F, fig.align='center', fig.cap="Sensitivity, Specificity and F1 scores breakdown"}
require(caret)
arima14_metrics = confusionMatrix(y_arima14_pred, reference = y_test)$byClass[1:3,c('Sensitivity', 'Specificity','F1')]

kable(arima14_metrics)
```

In summary, the result of this section means that even though ARIMA(1,4) and Sunspot Regression ARMA(1,4) perform better than the White Noise model in term of RMSE, they are not better in term of actual solar flare category classification prediction. This defection is probably linked to the fact that all of the models couldn't capture the peaks of the X-ray flux time series. In case of SARIMA(1,4,2,0,8), its RMSE is worse than White Noise, mostly due to overparameterization. 

# Conclusion Summary & Discussion

To summarize our findings in Section 3 and 4,

1. We find that there is correlation within the X-ray flux time series and that implies that it's possible to use the past data to predict the future solar flares. In addition, a seasonality every 8 observations is discovered by the smoothed periodogram.

2. ARMA(1, 4) and SARIMA(1,4,2,0,8) are the best fitted models in term of AIC. In addition, the cross correlation of the daily number of sunspots data and X-ray flux is significant and so we took advantage of this fact by fitting a Regression ARMA(1, 4) model.

3. While ARMA(1, 4) and Regression ARMA(1, 4) do better than White Noise in term of RMSE. For practical purpose of classifying future Solar Flare category, they didn't do better than White Noise model. The SARIMA model in fact performed worse than white noise in term of RMSE which might be due to overparameterization.

The bad performance is likely linked to the fact that none of the fitted models could correctly capture the peaks of the data. We suspect that the reason is that the sharp increase in intensities during solar flares can not be modeled accurately with only linear relationship among observations. As a consequence, a future work of exploring time series based on non-linear relationships is a reasonable direction to explore.


**Reference:**


[1] Robert H., David S. Stoffer.Time Series Analysis and Its Applications: With R Examples. Springer, 3rd ed, 2011.

[2] Chen et al, Identifying Solar Flare Precursors Using Time Series of SDO/HMI Images and SHARP Parameters, AGU, 2019

[3] Vlad Landa et al, Low Dimensional Convolutional Neural Network For Solar Flares GOES Time Series Classification, arXiv, 2021.

[4] Sunspots and Solar Flares, https://spaceplace.nasa.gov/solar-activity/en/

[5] What are the different types, or classes, of flares?, http://solar-center.stanford.edu/SID/activities/flare.html

[6] 2019 GOES X-ray flux data, https://satdat.ngdc.noaa.gov/sem/goes/data/avg/2019/

[7] 2019 Sunpot Count data, http://www.sidc.be/silso/datafiles